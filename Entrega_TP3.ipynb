{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1iLx2DRitxx"
      },
      "source": [
        "Universidad Torcuato Di Tella\n",
        "\n",
        "Licenciatura en Tecnología Digital\\\n",
        "**Tecnología Digital VI: Inteligencia Artificial**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSdBL2673KUX",
        "outputId": "24a2b7f8-3400-4da5-9a1f-64b5bc6111d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->torchaudio) (3.0.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchaudio\n",
        "!pip install  pydub\n",
        "!pip install wandb\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchaudio.datasets import GTZAN\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "import numpy as np\n",
        "import time\n",
        "import torchaudio.transforms as transforms\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAR3tiGci2-e"
      },
      "source": [
        "\n",
        "# TP3: Encodeador de música\n",
        "\n",
        "\n",
        "\n",
        "## Orden de pasos\n",
        "\n",
        "0. Elijan GPU para que corra mas rapido (RAM --> change runtime type --> T4 GPU)\n",
        "1. Descargamos el dataset y lo descomprimimos en alguna carpeta en nuestro drive.\n",
        "2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
        "3. Visualización de los archivos\n",
        "4. Clasificación\n",
        "5. Evaluación\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt4FEe853KUX"
      },
      "outputs": [],
      "source": [
        "project_name='Music_genre_classification'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU5G8mTE-5zM"
      },
      "source": [
        "### 2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5AUydgIxfwi",
        "outputId": "66f94668-6711-474b-a6c3-387b3ab16cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYLOe3isiV0b"
      },
      "source": [
        "data_dir es el path donde pusimos la carpeta genres. \"'//content/drive/MyDrive/Materias/TD6 - Inteligencia Artificial/TPs/2023/TP4/genres/'\" es un ejemplo. Modificar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kYMlPdYrzCi",
        "outputId": "915b7988-3a37-4040-a188-140951bb5187"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blues',\n",
              " 'rock',\n",
              " 'hiphop',\n",
              " 'reggae',\n",
              " 'country',\n",
              " 'disco',\n",
              " 'jazz',\n",
              " 'classical',\n",
              " 'metal',\n",
              " 'pop']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "data_dir='//content/drive/MyDrive/TP3 TD6/genres_5sec/'\n",
        "list_files=os.listdir(data_dir)\n",
        "classes=[]\n",
        "for file in list_files:\n",
        "  name='{}/{}'.format(data_dir,file)\n",
        "  if os.path.isdir(name):\n",
        "    classes.append(file)\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJxZV04XZtnP"
      },
      "outputs": [],
      "source": [
        "samplerate=22050\n",
        "def parse_genres(fname):\n",
        "    parts = fname.split('/')[-1].split('.')[0]\n",
        "    return parts #' '.join(parts[0])\n",
        "\n",
        "class MusicDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.files =[]\n",
        "        for c in classes:\n",
        "          self.files = self.files + [fname for fname in os.listdir(os.path.join(root,c)) if fname.endswith('.wav')]\n",
        "        self.classes = list(set(parse_genres(fname) for fname in self.files))\n",
        "        #self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        fname = self.files[i]\n",
        "\n",
        "        #img = self.transform(open_image(fpath))\n",
        "        genre = parse_genres(fname)\n",
        "        fpath = os.path.join(self.root,genre, fname)\n",
        "        class_idx = self.classes.index(genre)\n",
        "        audio = torchaudio.load(fpath)[0].squeeze()\n",
        "\n",
        "        return audio, class_idx\n",
        "dataset = MusicDataset(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDBqRCWT0p8j"
      },
      "source": [
        "### 3. Visualización de los archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiDa813SG-2f"
      },
      "outputs": [],
      "source": [
        "waveform,label= dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dr5Qhgk5sjL",
        "outputId": "ffbc18f7-fe9f-4dd0-e850-421aff017d6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(790, 100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed);\n",
        "val_size = 100\n",
        "test_size = 100\n",
        "train_size = len(dataset) - val_size - test_size\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "len(train_ds),len(val_ds),len(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBHjbBoo5sG1",
        "outputId": "c4d3857c-31d7-494b-c179-e4f4867fc879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 20\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "valid_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds,1, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXnHDpoYttX8"
      },
      "source": [
        "### 4. Clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcDC-phRXtMD"
      },
      "outputs": [],
      "source": [
        "class CNN_4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Definir la transformación MelSpectrogram\n",
        "        self.spectrogram_transform = transforms.MelSpectrogram(\n",
        "            sample_rate=22050,\n",
        "            n_fft=1024,\n",
        "            hop_length=512,\n",
        "            n_mels=64\n",
        "        )\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(27648, 32)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(32, 32)\n",
        "        self.fc3 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convertir waveform a espectrograma\n",
        "        batch_spectrograms = [self.spectrogram_transform(wav.squeeze(0)) for wav in x]\n",
        "        x = torch.stack(batch_spectrograms).unsqueeze(1).to(x.device)  # Agrega el canal\n",
        "\n",
        "        x = nn.Tanh()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
        "\n",
        "        x = nn.Tanh()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.Tanh()(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = nn.Tanh()(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryss1Hhm3KUf",
        "outputId": "5138da59-08d4-4a64-828f-2b758b852835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_4(\n",
            "  (spectrogram_transform): MelSpectrogram(\n",
            "    (spectrogram): Spectrogram()\n",
            "    (mel_scale): MelScale()\n",
            "  )\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=27648, out_features=32, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n",
            "Number of parameters: 895722\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CNN_4()\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "n = count_parameters(model)\n",
        "print(\"Number of parameters: %s\" % n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "jsRjx8rOuK72",
        "outputId": "822ddf6b-0b5b-4e12-f709-2a504319b9f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mestanibeda\u001b[0m (\u001b[33mestanibeda-universidad-torcuato-di-tella\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241110_132826-vv0wvcfm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock/runs/vv0wvcfm' target=\"_blank\">mejor modelo</a></strong> to <a href='https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock' target=\"_blank\">https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock/runs/vv0wvcfm' target=\"_blank\">https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock/runs/vv0wvcfm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock/runs/vv0wvcfm?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a7789262c50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "project_name='Modelo grupo Bedacarratz Gaido Kullock'\n",
        "wandb.login(key = \"903378b08bbf4bb7597553b9faa17b1eb2bacc01\")\n",
        "wandb.init(\n",
        "    project=project_name,\n",
        "    entity=\"\",\n",
        "    name=\"mejor modelo\",\n",
        "    config = {\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"epochs\": 10\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weWN67TzLIVI"
      },
      "source": [
        "Este codigo es para CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ga3vDJgTLIAN",
        "outputId": "a18101d0-a219-4ad8-a0be-81b3561c6378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/30], Train loss: 2.5721\n",
            "Epoch: [1/30], Valid loss: 2.1962, Valid accuracy: 0.2500\n",
            "Saving the best model at epoch 0!\n",
            "Epoch: [2/30], Train loss: 2.3811\n",
            "Epoch: [2/30], Valid loss: 2.0194, Valid accuracy: 0.3700\n",
            "Saving the best model at epoch 1!\n",
            "Epoch: [3/30], Train loss: 2.2512\n",
            "Epoch: [3/30], Valid loss: 1.8476, Valid accuracy: 0.4500\n",
            "Saving the best model at epoch 2!\n",
            "Epoch: [4/30], Train loss: 2.0916\n",
            "Epoch: [4/30], Valid loss: 1.7077, Valid accuracy: 0.5400\n",
            "Saving the best model at epoch 3!\n",
            "Epoch: [5/30], Train loss: 1.9018\n",
            "Epoch: [5/30], Valid loss: 1.6165, Valid accuracy: 0.4900\n",
            "Saving the best model at epoch 4!\n",
            "Epoch: [6/30], Train loss: 1.7008\n",
            "Epoch: [6/30], Valid loss: 1.5473, Valid accuracy: 0.5300\n",
            "Saving the best model at epoch 5!\n",
            "Epoch: [7/30], Train loss: 1.5511\n",
            "Epoch: [7/30], Valid loss: 1.4719, Valid accuracy: 0.5700\n",
            "Saving the best model at epoch 6!\n",
            "Epoch: [8/30], Train loss: 1.4158\n",
            "Epoch: [8/30], Valid loss: 1.4143, Valid accuracy: 0.6200\n",
            "Saving the best model at epoch 7!\n",
            "Epoch: [9/30], Train loss: 1.2921\n",
            "Epoch: [9/30], Valid loss: 1.3852, Valid accuracy: 0.5900\n",
            "Saving the best model at epoch 8!\n",
            "Epoch: [10/30], Train loss: 1.1793\n",
            "Epoch: [10/30], Valid loss: 1.3591, Valid accuracy: 0.5900\n",
            "Saving the best model at epoch 9!\n",
            "Epoch: [11/30], Train loss: 1.0696\n",
            "Epoch: [11/30], Valid loss: 1.3368, Valid accuracy: 0.5700\n",
            "Saving the best model at epoch 10!\n",
            "Epoch: [12/30], Train loss: 1.0142\n",
            "Epoch: [12/30], Valid loss: 1.3142, Valid accuracy: 0.5700\n",
            "Saving the best model at epoch 11!\n",
            "Epoch: [13/30], Train loss: 0.9734\n",
            "Epoch: [13/30], Valid loss: 1.2925, Valid accuracy: 0.6000\n",
            "Saving the best model at epoch 12!\n",
            "Epoch: [14/30], Train loss: 0.9295\n",
            "Epoch: [14/30], Valid loss: 1.2858, Valid accuracy: 0.6100\n",
            "Saving the best model at epoch 13!\n",
            "Epoch: [15/30], Train loss: 0.8876\n",
            "Epoch: [15/30], Valid loss: 1.2713, Valid accuracy: 0.5900\n",
            "Saving the best model at epoch 14!\n",
            "Epoch: [16/30], Train loss: 0.8436\n",
            "Epoch: [16/30], Valid loss: 1.2721, Valid accuracy: 0.6000\n",
            "Epoch: [17/30], Train loss: 0.8158\n",
            "Epoch: [17/30], Valid loss: 1.2698, Valid accuracy: 0.6100\n",
            "Saving the best model at epoch 16!\n",
            "Epoch: [18/30], Train loss: 0.7943\n",
            "Epoch: [18/30], Valid loss: 1.2654, Valid accuracy: 0.6200\n",
            "Saving the best model at epoch 17!\n",
            "Epoch: [19/30], Train loss: 0.7809\n",
            "Epoch: [19/30], Valid loss: 1.2537, Valid accuracy: 0.6100\n",
            "Saving the best model at epoch 18!\n",
            "Epoch: [20/30], Train loss: 0.7642\n",
            "Epoch: [20/30], Valid loss: 1.2571, Valid accuracy: 0.5800\n",
            "Epoch: [21/30], Train loss: 0.7377\n",
            "Epoch: [21/30], Valid loss: 1.2514, Valid accuracy: 0.6100\n",
            "Saving the best model at epoch 20!\n",
            "Epoch: [22/30], Train loss: 0.7235\n",
            "Epoch: [22/30], Valid loss: 1.2490, Valid accuracy: 0.5800\n",
            "Saving the best model at epoch 21!\n",
            "Epoch: [23/30], Train loss: 0.7253\n",
            "Epoch: [23/30], Valid loss: 1.2531, Valid accuracy: 0.5900\n",
            "Epoch: [24/30], Train loss: 0.7042\n",
            "Epoch: [24/30], Valid loss: 1.2573, Valid accuracy: 0.5900\n",
            "Epoch: [25/30], Train loss: 0.6963\n",
            "Epoch: [25/30], Valid loss: 1.2556, Valid accuracy: 0.6000\n",
            "Epoch: [26/30], Train loss: 0.7031\n",
            "Epoch: [26/30], Valid loss: 1.2592, Valid accuracy: 0.5700\n",
            "Epoch: [27/30], Train loss: 0.7004\n",
            "Epoch: [27/30], Valid loss: 1.2528, Valid accuracy: 0.6100\n",
            "Epoch: [28/30], Train loss: 0.6902\n",
            "Epoch: [28/30], Valid loss: 1.2515, Valid accuracy: 0.6100\n",
            "Epoch: [29/30], Train loss: 0.7008\n",
            "Epoch: [29/30], Valid loss: 1.2521, Valid accuracy: 0.6000\n",
            "Epoch: [30/30], Train loss: 0.6948\n",
            "Epoch: [30/30], Valid loss: 1.2486, Valid accuracy: 0.6100\n",
            "Saving the best model at epoch 29!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▇▇▆▆▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Valid Accuracy</td><td>▁▃▅▆▆▆▇█▇▇▇▇██▇████▇█▇▇▇█▇████</td></tr><tr><td>Valid Loss</td><td>█▇▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.69478</td></tr><tr><td>Valid Accuracy</td><td>0.61</td></tr><tr><td>Valid Loss</td><td>1.24863</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">mejor modelo</strong> at: <a href='https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock/runs/vv0wvcfm' target=\"_blank\">https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock/runs/vv0wvcfm</a><br/> View project at: <a href='https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock' target=\"_blank\">https://wandb.ai/estanibeda-universidad-torcuato-di-tella/Modelo%20grupo%20Bedacarratz%20Gaido%20Kullock</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241110_132826-vv0wvcfm/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import gc\n",
        "import numpy as np\n",
        "import wandb\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch.nn.functional as F\n",
        "import torchaudio.transforms as transforms\n",
        "\n",
        "# Configuración\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "valid_losses = []\n",
        "train_losses = []\n",
        "num_epochs = 30\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Versión 2: Adam + StepLR\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5) #\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "l1_lambda = 1e-4\n",
        "\n",
        "\n",
        "# Loop de entrenamiento\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_losses = []  # Reseteamos los train_losses para cada época\n",
        "\n",
        "    # Entrenamiento\n",
        "    for wav, genre_index in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        genre_index = genre_index.to(device)\n",
        "\n",
        "        # Forward y cálculo de pérdida\n",
        "        out = model(wav)\n",
        "        loss = loss_function(out.squeeze(), genre_index)\n",
        "\n",
        "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "        loss += l1_lambda * l1_norm  # Agrega la penalización L1 a la pérdida\n",
        "\n",
        "        # Backward y actualización de optimizador\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Almacenar pérdida\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Liberar memoria\n",
        "        del wav, genre_index, loss, out\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Cálculo de pérdida de entrenamiento de la época\n",
        "    train_loss_epoch = sum(train_losses) / len(train_losses)\n",
        "    print(f'Epoch: [{epoch + 1}/{num_epochs}], Train loss: {train_loss_epoch:.4f}')\n",
        "\n",
        "    # Validación\n",
        "    model.eval()\n",
        "    valid_losses_epoch = []\n",
        "    correct = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for wav, genre_index in valid_dl:\n",
        "            wav = wav.to(device)\n",
        "            genre_index = genre_index.to(device)\n",
        "\n",
        "            # Forward y cálculo de pérdida de validación\n",
        "            out = model(wav)\n",
        "            loss = loss_function(out.squeeze(), genre_index)\n",
        "\n",
        "            # Almacenar pérdida y realizar predicciones\n",
        "            valid_losses_epoch.append(loss.item())\n",
        "            pred = out.argmax(dim=-1).flatten()\n",
        "            correct += pred.eq(genre_index).sum().item()\n",
        "            y_true.extend(genre_index.cpu().numpy())\n",
        "            y_pred.extend(pred.cpu().numpy())\n",
        "\n",
        "            # Liberar memoria\n",
        "            del wav, genre_index, loss, out\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    # Cálculo de métricas de validación\n",
        "    valid_loss_epoch = sum(valid_losses_epoch) / len(valid_losses_epoch)\n",
        "    accuracy = correct / len(valid_dl.dataset)\n",
        "    print(f'Epoch: [{epoch + 1}/{num_epochs}], Valid loss: {valid_loss_epoch:.4f}, Valid accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Guardar en WandB\n",
        "    wandb.log({\"Train Loss\": train_loss_epoch, \"Valid Loss\": valid_loss_epoch, \"Valid Accuracy\": accuracy})\n",
        "\n",
        "    # Guardar mejor modelo\n",
        "    valid_losses.append(valid_loss_epoch)\n",
        "    if np.argmin(valid_losses) == epoch:\n",
        "        print(f'Saving the best model at epoch {epoch}!')\n",
        "        torch.save(model.state_dict(), 'best_model.ckpt')\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFwYdlWxCN0M"
      },
      "source": [
        "\n",
        "\n",
        "### 5. Evaluación\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6RFD17nU81b"
      },
      "outputs": [],
      "source": [
        "test_dl = DataLoader(test_ds,1,shuffle=True, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Pqtx-D0zAwa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38c72e4-0ed3-4ca8-c026-89f81d5dae4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-f502dbe71b99>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  S = torch.load('best_model.ckpt')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [30/30], Valid loss: 0.6948, Valid accuracy: 0.6800\n"
          ]
        }
      ],
      "source": [
        "# Load the best model\n",
        "S = torch.load('best_model.ckpt')\n",
        "model.load_state_dict(S)\n",
        "print('loaded!')\n",
        "\n",
        "# Run evaluation\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "correct = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for wav, genre_index in test_dl:\n",
        "        wav = wav.to(device)\n",
        "        genre_index = genre_index.to(device)\n",
        "\n",
        "        out = model(wav)\n",
        "\n",
        "        pred= out.argmax(dim=-1).flatten()\n",
        "        # append labels and predictions\n",
        "        correct += pred.eq(genre_index).sum().item()\n",
        "        y_true.extend(genre_index.cpu().numpy())\n",
        "        y_pred.extend(pred.cpu().numpy())\n",
        "\n",
        "accuracy =correct/ len(test_dl.dataset)\n",
        "print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, train_loss_epoch, accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA6O4xauAZFH"
      },
      "outputs": [],
      "source": [
        "waveform,label= test_dl.dataset[12]\n",
        "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(waveform.size(),samplerate,label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUg9zOkbAo6-"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(waveform, rate=22050)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnqTp_twAtH7"
      },
      "outputs": [],
      "source": [
        "wav= torch.unsqueeze(waveform, dim=0)\n",
        "model.to(device)\n",
        "wav =wav.to(device)\n",
        "out = model(wav)\n",
        "pred= out.argmax(dim=-1).flatten()\n",
        "classes[pred], classes[label]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}